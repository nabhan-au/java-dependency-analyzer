{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from pandas import DataFrame"
   ],
   "id": "b4db3f36cbd75903",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": "dir = \"\"",
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def list_directories(path):\n",
    "    # List only directories\n",
    "    directories = [os.path.join(path, d) for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "    return directories\n",
    "\n",
    "def list_files(directory):\n",
    "    # List only files\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    return files\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)  # Parse JSON data\n",
    "    return data\n",
    "\n",
    "def convert_dependency_format_to_list(data):\n",
    "    result = []\n",
    "    for dependency in data:\n",
    "        if \":\" in dependency['artifact']:\n",
    "            converted_artifact = \":\".join(dependency['artifact'].split(':')[0:2])\n",
    "            result.append(converted_artifact)\n",
    "    return list(set(result))        "
   ],
   "id": "48fce4ef7f1a4cce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "class ComparedResult:\n",
    "    def __init__(self, csv_file):\n",
    "        self.csv_file = csv_file\n",
    "        self.df = pd.read_csv(csv_file)    \n",
    "        \n",
    "    def get_timestamp(self, release_id):\n",
    "        artifact_id = \":\".join(release_id.split(\":\")[0:2])\n",
    "        version = release_id.split(\":\")[-1]\n",
    "        row = self.df[self.df['artifact_id'] == artifact_id]\n",
    "        row = row.iloc[0]\n",
    "        tags = ast.literal_eval(row['tags'])\n",
    "        versions = ast.literal_eval(row['versions'])\n",
    "        \n",
    "        compared_result_list = []\n",
    "        for entry in row[\"compared_result\"]:\n",
    "            compared_result_list.append(entry[0])\n",
    "            \n",
    "        for entry in versions:\n",
    "            if entry[\"name\"] == version:\n",
    "                return entry[\"ts\"]\n",
    "    \n",
    "        # Check in older_tags\n",
    "        for entry in tags:\n",
    "            if entry[\"name\"] == version:\n",
    "                iso_date = entry[\"date\"]\n",
    "                timestamp = int(datetime.strptime(iso_date, \"%Y-%m-%dT%H:%M:%SZ\").timestamp()) * 1000\n",
    "                return timestamp\n",
    "    \n",
    "        # If not found\n",
    "        return None\n",
    "    \n",
    "    def get_first_timestamp(self, release_id):\n",
    "        artifact_id = \":\".join(release_id.split(\":\")[0:2])\n",
    "        version = release_id.split(\":\")[-1]\n",
    "        row = self.df[self.df['artifact_id'] == artifact_id]\n",
    "        row = row.iloc[0]\n",
    "        tags = ast.literal_eval(row['tags'])\n",
    "        versions = ast.literal_eval(row['versions'])   \n",
    "        \n",
    "        success_file = [file.split(\".json\")[0] for file in list_files(dir + \"/\" + artifact_id)]\n",
    "            \n",
    "        version_with_ts = []\n",
    "        for entry in versions:\n",
    "            if entry[\"name\"] in success_file:\n",
    "                version_with_ts.append({\"name\": entry[\"name\"], \"ts\": int(entry[\"ts\"])})\n",
    "    \n",
    "        # Check in older_tags\n",
    "        for entry in tags:\n",
    "            if entry[\"name\"] in success_file:\n",
    "                iso_date = entry[\"date\"]\n",
    "                ts = int(datetime.strptime(iso_date, \"%Y-%m-%dT%H:%M:%SZ\").timestamp()) * 1000\n",
    "                if not any(existing_entry[\"name\"] == entry[\"name\"] for existing_entry in version_with_ts):\n",
    "                    version_with_ts.append({\"name\": entry[\"name\"], \"ts\": ts})\n",
    "            \n",
    "        sorted_version = sorted(version_with_ts, key=lambda x: x[\"ts\"])\n",
    "    \n",
    "        # If not found\n",
    "        return sorted_version[0][\"ts\"]\n",
    "    \n",
    "    def get_current_version_index(self, release_id):\n",
    "        artifact_id = \":\".join(release_id.split(\":\")[0:2])\n",
    "        version = release_id.split(\":\")[-1]\n",
    "        row = self.df[self.df['artifact_id'] == artifact_id]\n",
    "        row = row.iloc[0]\n",
    "        tags = ast.literal_eval(row['tags'])\n",
    "        versions = ast.literal_eval(row['versions'])   \n",
    "        \n",
    "        success_file = [file.split(\".json\")[0] for file in list_files(dir + \"/\" + artifact_id)]\n",
    "            \n",
    "        version_with_ts = []\n",
    "        for entry in versions:\n",
    "            if entry[\"name\"] in success_file:\n",
    "                version_with_ts.append({\"name\": entry[\"name\"], \"ts\": int(entry[\"ts\"])})\n",
    "    \n",
    "        # Check in older_tags\n",
    "        for entry in tags:\n",
    "            if entry[\"name\"] in success_file:\n",
    "                iso_date = entry[\"date\"]\n",
    "                ts = int(datetime.strptime(iso_date, \"%Y-%m-%dT%H:%M:%SZ\").timestamp()) * 1000\n",
    "                if not any(existing_entry[\"name\"] == entry[\"name\"] for existing_entry in version_with_ts):\n",
    "                    version_with_ts.append({\"name\": entry[\"name\"], \"ts\": ts})\n",
    "            \n",
    "        sorted_version = sorted(version_with_ts, key=lambda x: x[\"ts\"])\n",
    "        for i, entry in enumerate(sorted_version):\n",
    "            if entry[\"name\"] == version:\n",
    "                return i          \n",
    "        return None"
   ],
   "id": "549c77ffc19f8145",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Neo4jDriver:\n",
    "\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def get_timestamp(self, release_id):\n",
    "        query = \"\"\"\n",
    "        MATCH (r:Release {id: $release_id})\n",
    "        RETURN r.timestamp\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # Execute the query and return the results\n",
    "            results = session.run(query, release_id=release_id)\n",
    "            return [record[\"r.timestamp\"] for record in results][0]"
   ],
   "id": "56358cf0a467ffd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ProjectReport:\n",
    "    artifact = \"\"\n",
    "    dir = \"\"\n",
    "    timestamp = \"\"\n",
    "    introduce_unused_dependency = []\n",
    "    introduce_unused_dependency_but_import = []\n",
    "    unused_previously_used = []\n",
    "    unused_previously_used_but_import = []\n",
    "    unused_dependency = []\n",
    "    use_dependency = []\n",
    "    use_transitive_dependency = []\n",
    "    \n",
    "    def __init__(self, artifact, introduce_unused_dependency, introduce_unused_dependency_but_import, unused_previously_used, unused_previously_used_but_import, unused_dependency, unused_but_import, use_dependency, use_transitive_dependency):\n",
    "        self.artifact = artifact\n",
    "        self.introduce_unused_dependency = introduce_unused_dependency\n",
    "        self.introduce_unused_dependency_but_import = introduce_unused_dependency_but_import\n",
    "        self.unused_previously_used = unused_previously_used\n",
    "        self.unused_previously_used_but_import = unused_previously_used_but_import\n",
    "        self.unused_dependency = unused_dependency\n",
    "        self.unused_but_import = unused_but_import\n",
    "        self.use_dependency = use_dependency\n",
    "        self.use_transitive_dependency = use_transitive_dependency\n",
    "        \n",
    "    def convert_to_df(self):\n",
    "        artifact_id = \":\".join(self.artifact.split(\":\")[0:2])\n",
    "        version = self.artifact.split(\":\")[2]\n",
    "        data = {\n",
    "            \"artifact\": artifact_id,\n",
    "            \"version\": version,\n",
    "            \"introduce_unused_dependency\": len(self.introduce_unused_dependency),\n",
    "            \"introduce_unused_dependency_but_import\": len(self.introduce_unused_dependency_but_import),\n",
    "            \"introduce_unused_previously_used\": len(self.unused_previously_used),\n",
    "            \"introduce_unused_but_import_previously_used\": len(self.unused_previously_used_but_import),\n",
    "            \"unused_dependency\": len(self.unused_dependency),\n",
    "            \"unused_dependency_but_import\": len(self.unused_but_import),\n",
    "            \"use_dependency\": len(self.use_dependency),\n",
    "            \"use_transitive_dependency\": len(self.use_transitive_dependency),\n",
    "        }\n",
    "        return pd.DataFrame(data, index=[0])\n",
    "        "
   ],
   "id": "2640eefc243a2434",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list_directories(dir)",
   "id": "7794e7b04ecdee27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "success_project = pd.read_csv(dir + \"/success_project.csv\")\n",
    "# success_project = pd.read_csv(\"temp.csv\")\n",
    "success_path_list = []\n",
    "for index, row in success_project.iterrows():\n",
    "    success_path_list.append(row[\"artifact_id\"])\n",
    "\n",
    "success_path_list"
   ],
   "id": "2f264a8bacc898d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(success_path_list)",
   "id": "448c9a6b90970b1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "success_project",
   "id": "f9aa7f999df02a8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# success_project.to_csv(\"temp.csv\")",
   "id": "b1bd7e2566d20dab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# driver = Neo4jDriver(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")\n",
    "filtered_directories = []\n",
    "compare_result = ComparedResult(\"\")\n",
    "\n",
    "for directory in list_directories(dir):\n",
    "    if (directory.split(\"/\")[-1] in success_path_list):\n",
    "        filtered_directories.append(directory)\n",
    "\n",
    "project_result = {}\n",
    "count = 0\n",
    "for project_dir in filtered_directories:\n",
    "    list_of_files = list_files(project_dir)\n",
    "    data_with_timestamp = []\n",
    "    project_report = []\n",
    "    project_id = \":\".join(read_json_file(os.path.join(project_dir, list_of_files[0]))[\"projectArtifact\"].split(\":\")[0:2])\n",
    "    for file in list_of_files:\n",
    "        data = read_json_file(os.path.join(project_dir, file))\n",
    "        artifact_id = data[\"projectArtifact\"]\n",
    "        timestamp = compare_result.get_timestamp(artifact_id)\n",
    "        data_with_timestamp.append((data, timestamp))\n",
    "    data_with_timestamp.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for index, data in enumerate(data_with_timestamp):\n",
    "        current_data = data[0]\n",
    "        artifact_id = current_data[\"projectArtifact\"]\n",
    "        current_unused_dependency = current_data[\"projectUnusedDependencies\"]\n",
    "        current_use_dependency = current_data[\"projectUseDependencies\"]\n",
    "        current_use_transitive_dependency = current_data[\"projectUseTransitiveDependencies\"]\n",
    "        converted_unused_dependency = list(set(convert_dependency_format_to_list(current_unused_dependency)))\n",
    "        converted_use_dependency = list(set(convert_dependency_format_to_list(current_use_dependency)))\n",
    "        converted_use_transitive_dependency = list(set(convert_dependency_format_to_list(current_use_transitive_dependency)))\n",
    "        file_import_reports = current_data[\"fileImportReports\"]\n",
    "        \n",
    "        unused_import_artifact = []\n",
    "        for import_report in file_import_reports:\n",
    "            unused_import_report = import_report[\"unusedImportReport\"]\n",
    "            for unused_import in unused_import_report:\n",
    "                artifact = unused_import[\"artifact\"]\n",
    "                result = convert_dependency_format_to_list([artifact])\n",
    "                if len(result) > 0:\n",
    "                    unused_import_artifact.append(result[0])\n",
    "                    \n",
    "        introduce_unused_but_import = []\n",
    "        unused_but_import_previously_used = []\n",
    "        \n",
    "        # Count unused but imported\n",
    "        unused_but_imported = []\n",
    "        for unused_dependency in converted_unused_dependency:\n",
    "            if unused_dependency in unused_import_artifact:\n",
    "                unused_but_imported.append(unused_dependency)\n",
    "                \n",
    "        \n",
    "        # Count introduce unused dependency\n",
    "        introduce_unused = []\n",
    "        unused_previously_used = []\n",
    "        if index == 0:\n",
    "            # First version\n",
    "            for unused_dep in converted_unused_dependency:\n",
    "                introduce_unused.append(unused_dep)\n",
    "                if unused_dep in unused_import_artifact:\n",
    "                    introduce_unused_but_import.append(unused_dep)\n",
    "        else:\n",
    "            previous_data = data_with_timestamp[index - 1][0]\n",
    "            previous_unused_dependency = previous_data[\"projectUnusedDependencies\"]\n",
    "            previous_use_dependency = previous_data[\"projectUseDependencies\"]\n",
    "            previous_use_transitive_dependency = previous_data[\"projectUseTransitiveDependencies\"]\n",
    "            all_previous_dependency = previous_unused_dependency + previous_use_dependency + previous_use_transitive_dependency\n",
    "            all_previous_use_dependency = previous_use_dependency + previous_use_transitive_dependency\n",
    "            converted_all_previous_dependency = list(set(convert_dependency_format_to_list(all_previous_dependency)))\n",
    "            converted_all_previous_use_dependency = list(set(convert_dependency_format_to_list(all_previous_use_dependency)))\n",
    "            \n",
    "            for unused_dep in converted_unused_dependency:\n",
    "                if unused_dep not in converted_all_previous_dependency:\n",
    "                    introduce_unused.append(unused_dep)\n",
    "                    if unused_dep in unused_import_artifact:\n",
    "                        introduce_unused_but_import.append(unused_dep)\n",
    "                elif unused_dep in converted_all_previous_use_dependency:\n",
    "                    unused_previously_used.append(unused_dep)\n",
    "                    if unused_dep in unused_import_artifact:\n",
    "                        unused_but_import_previously_used.append(unused_dep)\n",
    "        \n",
    "        report = ProjectReport(artifact_id, introduce_unused, introduce_unused_but_import, unused_previously_used, unused_but_import_previously_used, converted_unused_dependency, unused_but_imported, converted_use_dependency, converted_use_transitive_dependency)\n",
    "        project_report.append(report)\n",
    "    project_result[project_id] = project_report\n",
    "\n",
    "print(len(project_result))"
   ],
   "id": "5c6bff710070c27a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_list = []\n",
    "\n",
    "for k, v in project_result.items():\n",
    "    for project in v:\n",
    "        df_list.append(project.convert_to_df())\n",
    "\n",
    "concat_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "concat_df[\"all_introduce\"] = concat_df[\"introduce_unused_dependency\"] + concat_df[\"introduce_unused_previously_used\"]\n",
    "concat_df[\"all_dependency\"] = concat_df[\"use_dependency\"] + concat_df[\"use_transitive_dependency\"] + concat_df[\"unused_dependency\"]\n",
    "concat_df"
   ],
   "id": "a2894d8190330348",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "concat_df_result = concat_df.groupby(\"artifact\").agg(\n",
    "    introduce_unused_dependency_sum=pd.NamedAgg(column=\"introduce_unused_dependency\", aggfunc=\"sum\"),\n",
    "    introduce_unused_dependency_but_import_sum=pd.NamedAgg(column=\"introduce_unused_dependency_but_import\", aggfunc=\"sum\"),\n",
    "    introduce_unused_previously_use = pd.NamedAgg(column=\"introduce_unused_previously_used\", aggfunc=\"sum\"),\n",
    "    introduce_unused_but_import_previously_used = pd.NamedAgg(column=\"introduce_unused_but_import_previously_used\", aggfunc=\"sum\"),\n",
    "    total_unused_dependency = pd.NamedAgg(column=\"unused_dependency\", aggfunc=\"sum\"),\n",
    "    total_unused_dependency_but_import = pd.NamedAgg(column=\"unused_dependency_but_import\", aggfunc=\"sum\"),\n",
    "    total_use_transitive_dependency = pd.NamedAgg(column=\"use_transitive_dependency\", aggfunc=\"sum\"),\n",
    "    median_unused_dependency = pd.NamedAgg(column=\"unused_dependency\", aggfunc=\"median\"),\n",
    "    average_unused_dependency=pd.NamedAgg(column=\"unused_dependency\", aggfunc=\"mean\"),\n",
    "    average_unused_dependency_but_import = pd.NamedAgg(column=\"unused_dependency_but_import\", aggfunc=\"mean\"),\n",
    "    average_use_transitive_dependency=pd.NamedAgg(column=\"use_transitive_dependency\", aggfunc=\"mean\"),\n",
    "    dependency_count = pd.NamedAgg(column=\"all_dependency\", aggfunc=\"mean\"),\n",
    "    version_count=pd.NamedAgg(column=\"version\", aggfunc=\"count\"),\n",
    ")\n",
    "\n",
    "concat_df_result[\"version_count\"] = concat_df_result[\"version_count\"]\n",
    "\n",
    "# Display the result\n",
    "# concat_df_result.to_csv(\"data/temp.csv\")\n",
    "concat_df_result"
   ],
   "id": "819affab98644719",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "statistics = {\n",
    "    \"min\": concat_df_result.min(numeric_only=True),\n",
    "    \"mean\": concat_df_result.mean(numeric_only=True),\n",
    "    \"median\": concat_df_result.median(numeric_only=True),\n",
    "    \"max\": concat_df_result.max(numeric_only=True),\n",
    "    \"total\": concat_df_result.sum(numeric_only=True),\n",
    "}\n",
    "stats_df = pd.DataFrame(statistics)\n",
    "\n",
    "# Display the statistics table\n",
    "stats_df"
   ],
   "id": "6640d9d7cbfe1d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "statistics = {\n",
    "    \"min\": concat_df.min(numeric_only=True),\n",
    "    \"mean\": concat_df.mean(numeric_only=True),\n",
    "    \"median\": concat_df.median(numeric_only=True),\n",
    "    \"max\": concat_df.max(numeric_only=True),\n",
    "    \"total\": concat_df.sum(numeric_only=True),\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame(statistics)\n",
    "\n",
    "# Display the statistics table\n",
    "stats_df"
   ],
   "id": "86530db7179111ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "group_df = concat_df.groupby(\"artifact\").sum()\n",
    "print(len(group_df[group_df[\"all_introduce\"] > 0])/len(group_df))"
   ],
   "id": "7c03ece1464d163a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(concat_df[concat_df[\"all_introduce\"] > 0])/len(concat_df)",
   "id": "5199ef5fdc6d53a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(len(group_df))",
   "id": "4e2d3030ca4e5b04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rq2_project_result = {}\n",
    "for k, v in project_result.items():\n",
    "    if k in concat_df[\"artifact\"].tolist():\n",
    "        rq2_project_result[k] = v"
   ],
   "id": "1e8ed3f650be4a90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RQ2",
   "id": "3c8e4390f877cd99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ArtifactExistReport:\n",
    "    def __init__(self, project_id, artifact_id, from_ts, to_ts, from_version, to_version, version_different, last_state):\n",
    "        self.project_id = project_id\n",
    "        self.artifact_id = artifact_id\n",
    "        self.from_ts = from_ts\n",
    "        self.to_ts = to_ts\n",
    "        self.last_state = last_state\n",
    "        self.from_version = from_version\n",
    "        self.to_version = to_version\n",
    "        self.version_different = version_different\n",
    "        \n",
    "    def convert_to_df(self):\n",
    "        duration = None\n",
    "        if self.to_ts != None:\n",
    "            duration = self.to_ts - self.from_ts\n",
    "        data = {\n",
    "            \"project_id\": self.project_id,\n",
    "            \"artifact\": self.artifact_id,\n",
    "            \"from_ts\": self.from_ts,\n",
    "            \"to_ts\": self.to_ts,\n",
    "            \"last_state\": self.last_state,\n",
    "            \"from_version\": self.from_version,\n",
    "            \"to_version\": self.to_version,\n",
    "            \"version_different\": self.version_different,\n",
    "            \"duration\": duration,\n",
    "        }\n",
    "        return pd.DataFrame(data, index=[0])\n",
    "    "
   ],
   "id": "b079933ce7485545",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# driver = Neo4jDriver(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")\n",
    "\n",
    "\n",
    "def find_evolution(current_index, last_index, project_result, unused_artifact_id, project_id):\n",
    "    from_ts = project_result[current_index].timestamp\n",
    "    from_version = project_result[current_index].artifact.split(\":\")[2]\n",
    "    for i in range(current_index + 1, last_index + 1):\n",
    "        current_project_result = project_result[i]\n",
    "        if unused_artifact_id in current_project_result.unused_dependency:\n",
    "            continue\n",
    "        if unused_artifact_id in current_project_result.use_dependency or unused_artifact_id in current_project_result.use_transitive_dependency:\n",
    "            to_version = current_project_result.artifact.split(\":\")[2]\n",
    "            return ArtifactExistReport(project_id, unused_artifact_id, from_ts, current_project_result.timestamp, from_version, to_version, i - current_index, \"use later\")\n",
    "        to_version = current_project_result.artifact.split(\":\")[2]\n",
    "        return ArtifactExistReport(project_id, unused_artifact_id, from_ts, current_project_result.timestamp, from_version, to_version, i - current_index, \"removed\")\n",
    "    return ArtifactExistReport(project_id, unused_artifact_id, from_ts, None, from_version, None, None, \"stay there\")\n",
    "        \n",
    "\n",
    "how_long_exist = {}\n",
    "for project_id, project_reports in rq2_project_result.items():\n",
    "    result = []\n",
    "    for project_report in project_reports:\n",
    "        ts =  compare_result.get_timestamp(project_report.artifact)\n",
    "        project_report.timestamp = ts\n",
    "        \n",
    "    last_index = len(project_reports) - 1\n",
    "    for index, project_report in enumerate(project_reports):\n",
    "        for current_unused in project_report.introduce_unused_dependency:\n",
    "            result.append(find_evolution(index, last_index, project_reports, current_unused, project_id))\n",
    "        for current_unused in project_report.unused_previously_used:\n",
    "            result.append(find_evolution(index, last_index, project_reports, current_unused, project_id))\n",
    "    if len(result) > 0:\n",
    "        how_long_exist[project_id] = result"
   ],
   "id": "36b4b7c186a97c00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "how_long_exist",
   "id": "61c516b558b6f117",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "report_df_list = []\n",
    "\n",
    "for k, v in how_long_exist.items():\n",
    "    for artifact_report in v:\n",
    "        report_df_list.append(artifact_report.convert_to_df())\n",
    "        \n",
    "artifact_reports = pd.concat(report_df_list, axis=0, ignore_index=True)\n",
    "artifact_reports"
   ],
   "id": "d1634d61edcc7723",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "group_by_state_artifact_report = artifact_reports.groupby(\"last_state\").agg(\n",
    "    count=pd.NamedAgg(column=\"artifact\", aggfunc=\"count\"),\n",
    ")"
   ],
   "id": "9a4e1871d68a9b7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "group_by_state_artifact_report",
   "id": "16f27e6609462a39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Find first introduction date",
   "id": "6685d1abaecb0e3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from datetime import datetime",
   "id": "8ee8e9c94e04e126",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = []\n",
    "compare_result = ComparedResult(\"data_with_date/success-compared-result-2.csv\")\n",
    "for project_id, project_reports in rq2_project_result.items():\n",
    "    for project_report in project_reports:\n",
    "        ts =  compare_result.get_timestamp(project_report.artifact)\n",
    "        project_report.timestamp = ts\n",
    "        \n",
    "    for index, project_report in enumerate(project_reports):\n",
    "        current_index = compare_result.get_current_version_index(project_report.artifact)\n",
    "        first_ts = compare_result.get_first_timestamp(project_report.artifact)\n",
    "        for current_unused in project_report.introduce_unused_dependency:\n",
    "            result.append({\"project_id\": project_id, \"artifact_id\": project_report.artifact, \"unused_dependency\": current_unused, \"timestamp\": project_report.timestamp, \"first_timestamp\": first_ts, \"version\": current_index + 1})\n",
    "        for current_unused in project_report.unused_previously_used:\n",
    "            result.append({\"project_id\": project_id, \"artifact_id\": project_report.artifact, \"unused_dependency\": current_unused, \"timestamp\": project_report.timestamp, \"first_timestamp\": first_ts, \"version\": current_index + 1})\n",
    "    \n",
    "    "
   ],
   "id": "5f4a7a96f8522b6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(result)\n",
    "df"
   ],
   "id": "ba24e3ef3057335e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for index, row in df.iterrows():\n",
    "    first_ts = datetime.fromtimestamp(row[\"first_timestamp\"]/1000)\n",
    "    current_ts = datetime.fromtimestamp(row[\"timestamp\"]/1000)\n",
    "    diff_time = current_ts - first_ts\n",
    "    df.at[index, \"diff_days\"] = diff_time.days\n",
    "    \n",
    "    year_diff = current_ts.year - first_ts.year\n",
    "    month_diff = current_ts.month - first_ts.month\n",
    "    total_month_diff = year_diff * 12 + month_diff\n",
    "    \n",
    "    df.at[index, \"diff_year\"] = year_diff + 1\n",
    "    df.at[index, \"diff_month\"] = total_month_diff"
   ],
   "id": "a2f1eed38f11f22a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "8cd19b4f1b27ef36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(df[df[\"diff_year\"] == 1])/len(df) * 100",
   "id": "dfa8e661efa8e3fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(df[df[\"version\"] == 1]) / len(df) * 100",
   "id": "a412ce1dba56f9b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Resolved artifact report",
   "id": "7270f9c071ddf9a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8057ebd50e606365"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resolved_artifact_report = artifact_reports[artifact_reports[\"last_state\"].isin([\"removed\", \"use later\"])]\n",
    "resolved_artifact_report['duration_day'] = resolved_artifact_report['duration']/(1000 * 60 * 60 * 24)\n",
    "resolved_artifact_report = resolved_artifact_report[[\"duration_day\", \"version_different\"]]\n",
    "resolved_artifact_report"
   ],
   "id": "fd515ca1f98156df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stats_table = resolved_artifact_report.agg(['min', 'mean', 'median', 'max'])\n",
    "\n",
    "stats_table_transposed = stats_table.T\n",
    "stats_table_transposed"
   ],
   "id": "35173ebf619424df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Removed artifact report",
   "id": "a2efc8085c0d9366"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "artifact_reports[artifact_reports[\"last_state\"] == \"removed\"]",
   "id": "550587a3991cc5f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "removed_artifact_report = artifact_reports[artifact_reports[\"last_state\"] == \"removed\"]\n",
    "removed_artifact_report['duration_day'] = removed_artifact_report['duration']/(1000 * 60 * 60 * 24)\n",
    "removed_artifact_report = removed_artifact_report[[\"duration_day\", \"version_different\"]]\n",
    "removed_artifact_report"
   ],
   "id": "de1083f2325fe3f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "removed_artifact_report.to_csv(\"removed_artifact_report.csv\")",
   "id": "23b08ec5ce00d5f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stats_table = removed_artifact_report.agg(['min', 'mean', 'median', 'max'])\n",
    "\n",
    "stats_table_transposed = stats_table.T\n",
    "stats_table_transposed"
   ],
   "id": "f90fd517c9fd7bf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Use later artifact report",
   "id": "228facdc97c2ca3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "artifact_reports[artifact_reports[\"last_state\"] == \"use later\"]",
   "id": "dd829d8681470c39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "use_later_artifact_report = artifact_reports[artifact_reports[\"last_state\"] == \"use later\"]\n",
    "use_later_artifact_report['duration_day'] = use_later_artifact_report['duration']/(1000 * 60 * 60 * 24)\n",
    "use_later_artifact_report = use_later_artifact_report[[\"duration_day\", \"version_different\"]]\n",
    "use_later_artifact_report"
   ],
   "id": "6efbdee641c27e52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "use_later_artifact_report.to_csv(\"use_later_artifact_report.csv\")",
   "id": "8d54e971bb603fda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stats_table = use_later_artifact_report.agg(['min', 'mean', 'median', 'max'])\n",
    "\n",
    "stats_table_transposed = stats_table.T\n",
    "stats_table_transposed"
   ],
   "id": "1d2a6ab23b701aae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Mann-Whiteney U test",
   "id": "7d4ac01fd70763a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install scipy",
   "id": "842382add34fb4a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import scipy.stats._mannwhitneyu",
   "id": "ea10681d2c88f2b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "u_statictic, p_value = mannwhitneyu(use_later_artifact_report['duration_day'].tolist(), removed_artifact_report['duration_day'].tolist(), alternative='two-sided')\n",
    "print(u_statictic, p_value)"
   ],
   "id": "2f8a971b21d9106e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "u_statictic, p_value = mannwhitneyu(use_later_artifact_report['version_different'].tolist(), removed_artifact_report['version_different'].tolist(), alternative='two-sided')\n",
    "print(u_statictic, p_value)"
   ],
   "id": "11f7598c133fdf6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plot graph",
   "id": "3befc071fb532cf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "version_different_violin_plot = DataFrame({\n",
    "    \"Never used and removed\": removed_artifact_report[\"version_different\"],\n",
    "    \"Use later\": use_later_artifact_report[\"version_different\"],\n",
    "})\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.violinplot(data=version_different_violin_plot)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "sns.despine()\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "35a8ccde5548df79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "version_duration_plot = DataFrame({\n",
    "    \"Never used and removed\": removed_artifact_report[\"duration_day\"],\n",
    "    \"Use later\": use_later_artifact_report[\"duration_day\"],\n",
    "})\n",
    "\n",
    "sns.violinplot(data=version_duration_plot)\n",
    "plt.ylim(0, None)\n",
    "plt.show()"
   ],
   "id": "c12196910a106c2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "removed_artifact_report[removed_artifact_report[\"version_different\"] < 0]",
   "id": "522d5f67395276dd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
